{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control Trait Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This notebook selects controls traits based on genetic correlation and heritability to the test traits of height and BMI in humans. The network colocalization of these control traits is then assessed with rat BMI.\n",
    "\n",
    "Note: this notebook is provided for informational purposes, and has not been tested. Some components of this pipeline were run in the command line or in RStudio.\n",
    "\n",
    "\n",
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T21:55:23.832467Z",
     "start_time": "2022-09-02T21:55:10.027438Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T21:55:37.992109Z",
     "start_time": "2022-09-02T21:55:37.989872Z"
    }
   },
   "outputs": [],
   "source": [
    "cwd =  os.path.dirname(os.path.dirname(os.getcwd()))\n",
    "DATADIR = os.path.join(cwd, \"Data/\")\n",
    "FIGDIR = os.path.join(cwd, \"Figures/rerun_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Identify control traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T21:55:55.836322Z",
     "start_time": "2022-09-02T21:55:55.280738Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "hr_raw_small=pd.read_csv(DATADIR + \"inputs/controls/ukb31063_h2_topline.02Oct2019.txt\", sep=\"\\t\")\n",
    "corr_raw_bmi=pd.read_csv(DATADIR + \"inputs/controls/data-2021-12-07_BMI.csv\", sep=\",\")\n",
    "corr_raw_ht=pd.read_csv(DATADIR + \"inputs/controls/data-2021-12-07_STANDING_HEIGHT.csv\",sep=\",\")\n",
    "corr_raw=pd.read_csv(DATADIR + \"inputs/controls/ukbb_geno_correlation_sig.r2.txt\", sep=\"\\t\")\n",
    "corr_bmi = corr_raw.loc[corr_raw[\"p2\"]=='21001_irnt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T22:00:44.511595Z",
     "start_time": "2022-09-02T22:00:44.509397Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_phenotype(pheno):\n",
    "    pheno_suff = pheno.split(\">\")[1]\n",
    "    return pheno_suff.split(\"<\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T22:02:19.817012Z",
     "start_time": "2022-09-02T22:02:19.804867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phenotype</th>\n",
       "      <th>description</th>\n",
       "      <th>h2_liability</th>\n",
       "      <th>h2_liability_se</th>\n",
       "      <th>h2_observed</th>\n",
       "      <th>h2_observed_se</th>\n",
       "      <th>h2_z</th>\n",
       "      <th>h2_p</th>\n",
       "      <th>h2_sig</th>\n",
       "      <th>confidence</th>\n",
       "      <th>...</th>\n",
       "      <th>sex</th>\n",
       "      <th>isNotPrimary</th>\n",
       "      <th>isBadPower</th>\n",
       "      <th>isLowNeff</th>\n",
       "      <th>isMidNeff</th>\n",
       "      <th>isExtremeSE</th>\n",
       "      <th>isHighSE</th>\n",
       "      <th>isSexBias</th>\n",
       "      <th>isBadOrdinal</th>\n",
       "      <th>isNumericOrdinal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001_irnt</td>\n",
       "      <td>Food weight</td>\n",
       "      <td>0.068818</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>0.068818</td>\n",
       "      <td>0.016857</td>\n",
       "      <td>4.082528</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>z4</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>both_sexes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002_irnt</td>\n",
       "      <td>Energy</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.064783</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>4.104249</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>z4</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>both_sexes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003_irnt</td>\n",
       "      <td>Protein</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>0.034543</td>\n",
       "      <td>0.014619</td>\n",
       "      <td>2.362892</td>\n",
       "      <td>0.009066</td>\n",
       "      <td>nominal</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>both_sexes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004_irnt</td>\n",
       "      <td>Fat</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.055197</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>3.021937</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>nominal</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>both_sexes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005_irnt</td>\n",
       "      <td>Carbohydrate</td>\n",
       "      <td>0.051744</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.051744</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>3.369359</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>nominal</td>\n",
       "      <td>high</td>\n",
       "      <td>...</td>\n",
       "      <td>both_sexes</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     phenotype   description  h2_liability  h2_liability_se  h2_observed  \\\n",
       "0  100001_irnt   Food weight      0.068818         0.016857     0.068818   \n",
       "1  100002_irnt        Energy      0.064783         0.015784     0.064783   \n",
       "2  100003_irnt       Protein      0.034543         0.014619     0.034543   \n",
       "3  100004_irnt           Fat      0.055197         0.018265     0.055197   \n",
       "4  100005_irnt  Carbohydrate      0.051744         0.015357     0.051744   \n",
       "\n",
       "   h2_observed_se      h2_z      h2_p   h2_sig confidence  ...         sex  \\\n",
       "0        0.016857  4.082528  0.000022       z4       high  ...  both_sexes   \n",
       "1        0.015784  4.104249  0.000020       z4       high  ...  both_sexes   \n",
       "2        0.014619  2.362892  0.009066  nominal       high  ...  both_sexes   \n",
       "3        0.018265  3.021937  0.001256  nominal       high  ...  both_sexes   \n",
       "4        0.015357  3.369359  0.000377  nominal       high  ...  both_sexes   \n",
       "\n",
       "   isNotPrimary  isBadPower  isLowNeff  isMidNeff  isExtremeSE  isHighSE  \\\n",
       "0         False       False      False      False        False     False   \n",
       "1         False       False      False      False        False     False   \n",
       "2         False       False      False      False        False     False   \n",
       "3         False       False      False      False        False     False   \n",
       "4         False       False      False      False        False     False   \n",
       "\n",
       "   isSexBias  isBadOrdinal  isNumericOrdinal  \n",
       "0      False         False             False  \n",
       "1      False         False             False  \n",
       "2      False         False             False  \n",
       "3      False         False             False  \n",
       "4      False         False             False  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_raw_small.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Subset heritability (Hr) table to get list of traits with comparable heritability- no correlation taken into account\n",
    "https://nealelab.github.io/UKBB_ldsc/h2_browser.html\n",
    "explanation of variables in hr table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T22:08:27.216523Z",
     "start_time": "2022-09-02T22:08:27.206100Z"
    }
   },
   "outputs": [],
   "source": [
    "corr_raw_bmi[\"Description\"] = corr_raw_bmi[\"Phenotype 1\"].apply(extract_phenotype)\n",
    "corr_raw_ht[\"Description\"] = corr_raw_ht[\"Phenotype 1\"].apply(extract_phenotype)\n",
    "\n",
    "hr_raw_small = hr_raw_small[hr_raw_small.sex=='both_sexes']\n",
    "#reformat so can be selected for in same way as hr_raw_small as the phenotypes are listed differently\n",
    "hr_raw_small=hr_raw_small.loc[hr_raw_small.description.isin(corr_raw_bmi.Description)]\n",
    "hr_raw_small=hr_raw_small.loc[hr_raw_small.description.isin(corr_raw_ht.Description)]\n",
    "\n",
    "\n",
    "hr_tbl_binary=hr_raw_small.loc[(hr_raw_small.isBinary) & (hr_raw_small.h2_liability>=0.15)]\n",
    "hr_tbl_cont=hr_raw_small.loc[(~hr_raw_small.isBinary) & (hr_raw_small.variable_type !='ordinal') & (hr_raw_small.h2_observed>=0.15)]\n",
    "\n",
    "hr_tbl_cont=hr_tbl_cont.loc[(hr_tbl_cont.confidence==\"high\") | (hr_tbl_cont.confidence==\"medium\")]\n",
    "hr_tbl_binary=hr_tbl_binary.loc[(hr_tbl_binary.confidence==\"high\") | (hr_tbl_binary.confidence==\"medium\")]\n",
    "\n",
    "hr_tbl=pd.concat([hr_tbl_cont,hr_tbl_binary], axis=0)\n",
    "\n",
    "corr_bmi=corr_raw_bmi.loc[corr_raw_bmi.Description.isin(hr_tbl.description)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Download summary statistics for control traits\n",
    "\n",
    "after trait list of traits is found, need to use table from the version 3 of the Neale lab's datasets\n",
    "https://docs.google.com/spreadsheets/d/1kvPoupSzsSFBNSztMzl04xMoSC3Kcx3CrjVf4yBmESU/edit#gid=227859291\n",
    "file downloaded  to xlsx file as UKBB_GWAS_Imputed_v3-File_Manifest_Release_20180731.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T22:26:08.348162Z",
     "start_time": "2022-09-02T22:26:08.341555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phenotype Code</th>\n",
       "      <th>Phenotype Description</th>\n",
       "      <th>UK Biobank Data Showcase Link</th>\n",
       "      <th>Sex</th>\n",
       "      <th>File</th>\n",
       "      <th>wget command</th>\n",
       "      <th>AWS File</th>\n",
       "      <th>Dropbox File</th>\n",
       "      <th>md5s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>README</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>README</td>\n",
       "      <td>wget https://broad-ukb-sumstats-us-east-1.s3.a...</td>\n",
       "      <td>https://broad-ukb-sumstats-us-east-1.s3.amazon...</td>\n",
       "      <td>https://www.dropbox.com/s/wro30igqkmit5ig/READ...</td>\n",
       "      <td>bd14f2be665e6c915a3f6cee0a67b8dc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>MD5 Values for files in this manifest (excludi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2018_gwas_imputed_md5.txt</td>\n",
       "      <td>wget https://broad-ukb-sumstats-us-east-1.s3.a...</td>\n",
       "      <td>https://broad-ukb-sumstats-us-east-1.s3.amazon...</td>\n",
       "      <td>https://www.dropbox.com/s/dakt3shhn8b6wqr/2018...</td>\n",
       "      <td>d3e8743c4129f7e126ad7071d6e27563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>List of European samples</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both_sexes</td>\n",
       "      <td>european_samples.tsv.bgz</td>\n",
       "      <td>wget https://broad-ukb-sumstats-us-east-1.s3.a...</td>\n",
       "      <td>https://broad-ukb-sumstats-us-east-1.s3.amazon...</td>\n",
       "      <td>https://www.dropbox.com/s/bvnd723tl67lh8v/euro...</td>\n",
       "      <td>defb726a12659e7f0bc1a3057115a45a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>List of samples used in GWAS - both_sexes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>both_sexes</td>\n",
       "      <td>samples.both_sexes.tsv.bgz</td>\n",
       "      <td>wget https://broad-ukb-sumstats-us-east-1.s3.a...</td>\n",
       "      <td>https://broad-ukb-sumstats-us-east-1.s3.amazon...</td>\n",
       "      <td>https://www.dropbox.com/s/ypcmzukh2vwhtkh/samp...</td>\n",
       "      <td>9b5f931bd5df80a725946958d4afa85f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>List of samples used in GWAS - female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>female</td>\n",
       "      <td>samples.female.tsv.bgz</td>\n",
       "      <td>wget https://broad-ukb-sumstats-us-east-1.s3.a...</td>\n",
       "      <td>https://broad-ukb-sumstats-us-east-1.s3.amazon...</td>\n",
       "      <td>https://www.dropbox.com/s/nnn2zc3z5uqmlra/samp...</td>\n",
       "      <td>ca366bde28145eb4d93dc9b120754f25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Phenotype Code                              Phenotype Description  \\\n",
       "0            NaN                                             README   \n",
       "1            NaN  MD5 Values for files in this manifest (excludi...   \n",
       "2            NaN                           List of European samples   \n",
       "3            NaN          List of samples used in GWAS - both_sexes   \n",
       "4            NaN              List of samples used in GWAS - female   \n",
       "\n",
       "  UK Biobank Data Showcase Link         Sex                        File  \\\n",
       "0                           NaN         NaN                      README   \n",
       "1                           NaN         NaN   2018_gwas_imputed_md5.txt   \n",
       "2                           NaN  both_sexes    european_samples.tsv.bgz   \n",
       "3                           NaN  both_sexes  samples.both_sexes.tsv.bgz   \n",
       "4                           NaN      female      samples.female.tsv.bgz   \n",
       "\n",
       "                                        wget command  \\\n",
       "0  wget https://broad-ukb-sumstats-us-east-1.s3.a...   \n",
       "1  wget https://broad-ukb-sumstats-us-east-1.s3.a...   \n",
       "2  wget https://broad-ukb-sumstats-us-east-1.s3.a...   \n",
       "3  wget https://broad-ukb-sumstats-us-east-1.s3.a...   \n",
       "4  wget https://broad-ukb-sumstats-us-east-1.s3.a...   \n",
       "\n",
       "                                            AWS File  \\\n",
       "0  https://broad-ukb-sumstats-us-east-1.s3.amazon...   \n",
       "1  https://broad-ukb-sumstats-us-east-1.s3.amazon...   \n",
       "2  https://broad-ukb-sumstats-us-east-1.s3.amazon...   \n",
       "3  https://broad-ukb-sumstats-us-east-1.s3.amazon...   \n",
       "4  https://broad-ukb-sumstats-us-east-1.s3.amazon...   \n",
       "\n",
       "                                        Dropbox File  \\\n",
       "0  https://www.dropbox.com/s/wro30igqkmit5ig/READ...   \n",
       "1  https://www.dropbox.com/s/dakt3shhn8b6wqr/2018...   \n",
       "2  https://www.dropbox.com/s/bvnd723tl67lh8v/euro...   \n",
       "3  https://www.dropbox.com/s/ypcmzukh2vwhtkh/samp...   \n",
       "4  https://www.dropbox.com/s/nnn2zc3z5uqmlra/samp...   \n",
       "\n",
       "                                md5s  \n",
       "0   bd14f2be665e6c915a3f6cee0a67b8dc  \n",
       "1  d3e8743c4129f7e126ad7071d6e27563   \n",
       "2   defb726a12659e7f0bc1a3057115a45a  \n",
       "3   9b5f931bd5df80a725946958d4afa85f  \n",
       "4   ca366bde28145eb4d93dc9b120754f25  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manifest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-09-02T22:43:43.657322Z",
     "start_time": "2022-09-02T22:43:43.546332Z"
    }
   },
   "outputs": [],
   "source": [
    "manifest=pd.read_csv(DATADIR+\"inputs/controls/UKBB_GWAS_Imputed_v3-File_Manifest_Release_20180731.csv\", sep=\",\", encoding = 'unicode_escape')\n",
    "man_subset = manifest.loc[(manifest.Sex=='both_sexes') & (manifest[\"Phenotype Code\"].isin(hr_tbl.phenotype))]\n",
    "wget_ls = pd.DataFrame(man_subset[\"wget command\"])\n",
    "wget_ss= wget_ls.merge(manifest, on=\"wget command\", how=\"left\")\n",
    "ss_type=hr_tbl.loc[hr_tbl.description.isin(wget_ss[\"Phenotype Description\"])]\n",
    "wget_ls.to_csv(\"neale_lab_impupted_wget_cmds.sh\", sep=\"\\b\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Download all the summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#download all the raw files- creates .tsv.bgz files\n",
    "bash neale_imputed_wget_cmds.sh\n",
    "#download neale variants catalog\n",
    "wget https://broad-ukb-sumstats-us-east-1.s3.amazonaws.com/round2/annotations/variants.tsv.bgz -O neale_variants.tsv.bgz\n",
    "#unzip the neale_variants file and raw GWAS results\n",
    "gunzip -c -q \"$file\" >> neale_gunzip/\"${file%.tsv.bgz}\".tsv\n",
    "#convert to RSID file for running in pascal\n",
    "#AssignRSID.py in below cell\n",
    "python AssignRSID.py \"$file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "AssignRSID.py\n",
    "```\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "outfile = sys.argv[1]\n",
    "outfile = \"neale_rsid/\" + outfile[0:len(outfile)-31]+\"_RSID.txt\"\n",
    "reads = pd.read_csv(sys.argv[1], sep=\"\\t\", error_bad_lines=False,low_memory=False)\n",
    "\n",
    "mapping_df = pd.read_csv(\"neale_variants.tsv\", sep=\"\\t\", low_memory=False)\n",
    "\n",
    "mapping = dict(zip(mapping_df['variant'].tolist(),mapping_df['rsid'].tolist()))\n",
    "reads['rsid']=reads['variant'].map(mapping)\n",
    "reads_rmNAN=reads.dropna(subset=['rsid'])\n",
    "reads_rmNAN.head()\n",
    "reads_rmNAN= reads_rmNAN[['rsid','pval']]\n",
    "reads_rmNAN.to_csv(outfile, sep = \"\\t\", index=False)\n",
    "exit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PASCAL for all control traits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "#run pascal on RSID file\n",
    "./Pascal --pval=\"$file\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "#run netcoloc on pascal file using rat BMI seed genes previous calculated\n",
    "#netcoloc_runscript.py in below cell\n",
    "bash netcoloc_runscript.py \"$file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Perform Network Colocalization between rat BMI and control traits\n",
    "netcoloc_runscript.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import sys\n",
    "current_time = datetime.datetime.now() \n",
    "print(current_time)\n",
    "mo_str= str(current_time.month)\n",
    "if (len(mo_str)==1):\n",
    "    mo_str='0'+ mo_str\n",
    "day_str= str(current_time.day)\n",
    "if (len(day_str)==1):\n",
    "    day_str='0'+ day_str\n",
    "date= str(current_time.year) + mo_str + day_str\n",
    "\n",
    "#define path\n",
    "#DATADIR= \"\"\n",
    "trait= 'rat_BMI'\n",
    "out_dir= '~' + date\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "human_file_path = sys.argv[1]\n",
    "human_raw_file = human_file_path\n",
    "rat_raw_file ='ratBMI_seed_relaxed.txt'\n",
    "out_network = human_file_path[0:(len(human_file_path)-51)] + '_Neale_sampled_NetColocTo_'+trait + \"_relaxed_unsampled\"\n",
    "overlap_label= human_file_path[0:(len(human_file_path)-51)] + '\\t'+trait\n",
    "#change to 0, 51 before restarting the jobs\n",
    "out_network_file = out_dir + \"/\" + out_network + '.txt'\n",
    "out_overlap_file = out_dir + '/' + 'network_overlap.txt'\n",
    "out_z_random_file= out_dir + '/' + 'sampling_z_random_'+out_network+'.txt'\n",
    "out_z_file= out_dir+ '/' + 'sampling_z_'+out_network+'.txt'\n",
    "out_z_final_file= out_dir + '/'+'final_z'+out_network+'.txt'\n",
    "#------------------ [2]\n",
    "# load required packages (netcoloc)\n",
    "import pandas as pd\n",
    "from netcoloc import netprop_zscore, netprop\n",
    "import ndex2\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "import getpass\n",
    "import ndex2\n",
    "\n",
    "# latex rendering of text in graphs\n",
    "import matplotlib as mpl\n",
    "mpl.rc('text', usetex = False)\n",
    "mpl.rc('font', family = 'serif')\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['font.family'] = 'sans-serif'\n",
    "rcParams['font.sans-serif'] = ['Arial']\n",
    "\n",
    "sns.set(font_scale=1.4)\n",
    "sns.set_style('white')\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 15, \"ytick.major.size\": 15})\n",
    "plt.rcParams['svg.fonttype'] = 'none'\n",
    "\n",
    "import sys\n",
    "sys.path.append('../netcoloc/')\n",
    "\n",
    "from netcoloc import netprop_zscore\n",
    "from netcoloc import netprop\n",
    "from netcoloc import network_colocalization\n",
    "\n",
    "import imp\n",
    "imp.reload(netprop_zscore)\n",
    "imp.reload(netprop)\n",
    "imp.reload(network_colocalization)\n",
    "# set random seed to enable reproducibility between runs\n",
    "import random\n",
    "np.random.seed(1)\n",
    "#------------------ [3]\n",
    "#read in data files (netcoloc)\n",
    "hm_df = pd.read_csv(human_raw_file, sep=\"\\t\")\n",
    "rn_df = pd.read_csv(rat_raw_file,sep=\"\\t\")\n",
    "rn_df.columns = ['gene_symbol']\n",
    "rn_df.index=rn_df['gene_symbol']\n",
    "rn_genes = rn_df.index.tolist()\n",
    "#------------------ [4]\n",
    "#read in the interactome\n",
    "#interactome_uuid='4de852d9-9908-11e9-bcaf-0ac135e8bacf' # for PCNet\n",
    "interactome_uuid='880c7d8c-f5ad-11ec-ac45-0ac135e8bacf' #for rat STRING\n",
    "ndex_server='public.ndexbio.org'\n",
    "ndex_user= NA #insert user as string\n",
    "ndex_password= NA #insert pass as string\n",
    "G_PC = ndex2.create_nice_cx_from_server(\n",
    "            ndex_server, \n",
    "            username=ndex_user, \n",
    "            password=ndex_password, \n",
    "            uuid=interactome_uuid\n",
    "        ).to_networkx()\n",
    "nodes = list(G_PC.nodes)\n",
    "pc_nodes = list(G_PC.nodes)\n",
    "#------------------ [5]\n",
    "# pre calculate mats used for netprop... this step takes a few minutes, more for denser interactomes\n",
    "w_prime = netprop.get_normalized_adjacency_matrix(G_PC, conserve_heat=True,weighted=False)\n",
    "w_double_prime = netprop.get_individual_heats_matrix(w_prime, alpha=.5)\n",
    "#------------------ [6]\n",
    "rn_genes = list(np.intersect1d(rn_genes,pc_nodes))\n",
    "#------------------ [7]\n",
    "#format human data file - subset to significant gene associations (0.05 corrected by bonferroni)\n",
    "#df[df.Length > 7] df.column.isin(values)\n",
    "alpha= 0.05\n",
    "m=22136\n",
    "N=500\n",
    "alpha_corrected = alpha/m\n",
    "\n",
    "print(len(hm_df))\n",
    "hm_df_subset=hm_df[hm_df.gene_symbol.isin(pc_nodes)]\n",
    "hm_df_subset=hm_df[hm_df.pvalue<=(alpha_corrected)]\n",
    "print(len(hm_df_subset))\n",
    "hm_genes=hm_df_subset.gene_symbol.tolist()\n",
    "print(len(hm_genes))\n",
    "#hm_df_subset = hm_df_subset.sort_values('pvalue',ascending = True).head(500)\n",
    "#------------------ [8]\n",
    "indiv_heats=w_double_prime\n",
    "#------------------ [9]\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"Functions for getting z-scores from network propagation.\n",
    "\"\"\"\n",
    "\n",
    "# External library imports\n",
    "import os\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import ndex2\n",
    "# Internal module convenience imports\n",
    "from netcoloc.netcoloc_utils import *\n",
    "from netcoloc.netprop import *\n",
    "import random as rn\n",
    "\n",
    "\n",
    "def netprop_zscore(seed_gene_file, seed_gene_file_delimiter=None, num_reps=10, alpha=0.5, minimum_bin_size=10,\n",
    "                   interactome_file=None, interactome_uuid='f93f402c-86d4-11e7-a10d-0ac135e8bacf',\n",
    "                   ndex_server='public.ndexbio.org', ndex_user=None, ndex_password=None, out_name='out',\n",
    "                   save_z_scores=True, save_final_heat=True, save_random_final_heats=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Performs network heat propagation on the given interactome with the given\n",
    "    seed genes, then returns the z-scores of the final heat values of each node\n",
    "    in the interactome.\n",
    "\n",
    "    The z-scores are calculated based on a null model, which is built by running\n",
    "    the network propagation multiple times using randomly selected seed genes\n",
    "    with similar degree distributions to the original seed gene set.\n",
    "\n",
    "    This method returns a tuple containing the following:\n",
    "\n",
    "    * :py:class:`pandas.Series` containing z-scores for each gene. Gene names comprise the index column\n",
    "    * :py:class:`numpy.ndarray` containing square matrix where each row contains the final heat scores\n",
    "      for each gene from a network propagation from random seed genes\n",
    "\n",
    "    :param seed_gene_file: Location of file containing a delimited list of\n",
    "            seed genes\n",
    "    :type seed_gene_file: str\n",
    "    :param seed_gene_file_delimiter: Delimiter used to separate genes in seed\n",
    "                                     gene file. Default any whitespace\n",
    "    :type seed_gene_file_delimiter: str\n",
    "    :param num_reps: Number of times the network propagation algorithm should\n",
    "            be run using random seed genes in order to build the null model\n",
    "    :type num_reps: int\n",
    "    :param alpha: Number between 0 and 1. Denotes the importance of the\n",
    "            propagation step in the network propagation, as opposed to the step\n",
    "            where heat is added to seed genes only. Recommended to be 0.5 or\n",
    "            greater\n",
    "    :type alpha: float\n",
    "    :param minimum_bin_size: minimum number of genes that should be in\n",
    "            each degree matching bin.\n",
    "    :type minimum_bin_size: int\n",
    "    :param interactome_file: Location of file containing the interactome in\n",
    "            NetworkX gpickle format. Either the interactome_file argument or the\n",
    "            interactome_uuid argument must be defined.\n",
    "    :type interactome_file: str\n",
    "    :param interactome_uuid: UUID of the interactome on NDEx. Either the\n",
    "            interactome_file argument or the interactome_uuid argument must be\n",
    "            defined. (Default: The UUID of PCNet, the Parsimonious Composite\n",
    "            Network: f93f402c-86d4-11e7-a10d-0ac135e8bacf)\n",
    "    :type interactome_uuid: str\n",
    "    :param ndex_server: NDEx server on which the interactome is stored.\n",
    "            Only needs to be defined if interactome_uuid is defined\n",
    "    :type ndex_server: str\n",
    "    :param ndex_user: NDEx user that the interactome belongs to. Only\n",
    "            needs to be defined if interactome_uuid is defined, and the\n",
    "            interactome is private\n",
    "    :type ndex_user: str\n",
    "    :param ndex_password: password of the NDEx user's account. Only needs\n",
    "            to be defined if interactome_uuid is defined, and the interactome is\n",
    "            private\n",
    "    :type ndex_password: str\n",
    "    :param out_name: Prefix for saving output files\n",
    "    :type out_name: str\n",
    "    :param save_z_scores:\n",
    "    :param save_final_heat: If ``True``, then the raw network\n",
    "            propagation heat scores for the original seed gene set will be saved\n",
    "            in the form of a tsv file in the current directory\n",
    "    :type save_final_heat: bool\n",
    "    :param save_random_final_heats: If ``True``, then the raw\n",
    "            network propagation heat scores for every repetition of the\n",
    "            algorithm using random seed genes will be saved in the form of a tsv\n",
    "            file in the current directory. (Beware: This can be a large file if\n",
    "            num_reps is large.)\n",
    "    :type save_random_final_heats: bool\n",
    "    :param verbose: If ``True``, then progress information will\n",
    "            be logged. Otherwise, nothing will be printed\n",
    "    :return: (:py:class:`pandas.Series`, :py:class:`numpy.ndarray`)\n",
    "    :rtype: tuple\n",
    "    :raises TypeError: If neither interactome_file or interactome_uuid is provided or if\n",
    "                       **num_reps** is not an ``int``\n",
    "    \"\"\"\n",
    "    # Process arguments\n",
    "\n",
    "    # seed_gene_file\n",
    "    seed_gene_file = os.path.abspath(seed_gene_file)\n",
    "    # num_reps\n",
    "    try:\n",
    "        num_reps = int(num_reps)\n",
    "    except TypeError:\n",
    "        raise TypeError(\"The num_reps argument should be an integer\")\n",
    "    # int_file and int_uuid\n",
    "    if interactome_file is None and interactome_uuid is None:\n",
    "        raise TypeError(\"Either interactome_file or interactome_uuid argument must be provided\")\n",
    "\n",
    "    # Load interactome\n",
    "    if verbose:\n",
    "        print('Loading interactome')\n",
    "    if interactome_file is not None:\n",
    "        interactome_file = os.path.abspath(interactome_file)\n",
    "        # interactome = nx.Graph()\n",
    "        interactome = nx.read_gpickle(interactome_file)\n",
    "    else:\n",
    "        interactome = ndex2.create_nice_cx_from_server(\n",
    "            ndex_server,\n",
    "            username=ndex_user,\n",
    "            password=ndex_password,\n",
    "            uuid=interactome_uuid\n",
    "        ).to_networkx()\n",
    "    if 'None' in interactome.nodes():\n",
    "        interactome.remove_node('None')\n",
    "    nodes = list(interactome.nodes)\n",
    "\n",
    "    # Log interactome num nodes and edges for diagnostic purposes\n",
    "    if verbose:\n",
    "        print('Number of nodes: ' + str(len(interactome.nodes)))\n",
    "        print('Number of edges: ' + str(len(interactome.edges)))\n",
    "\n",
    "    # Load seed genes\n",
    "    seed_file = open(seed_gene_file, 'r')\n",
    "    seed_genes = list(np.intersect1d(nodes, seed_file.read().split(seed_gene_file_delimiter)))\n",
    "    if verbose:\n",
    "        print('\\nNumber of seed genes in interactome: ' + str(len(seed_genes)))\n",
    "\n",
    "    # Calculate individual_heats_matrix from interactome\n",
    "    if verbose:\n",
    "        print('\\nCalculating w_prime')\n",
    "    w_prime = get_normalized_adjacency_matrix(interactome, conserve_heat=True)\n",
    "    if verbose:\n",
    "        print('\\nCalculating individual_heats_matrix')\n",
    "    individual_heats_matrix = get_individual_heats_matrix(w_prime, alpha)\n",
    "\n",
    "    # Calculate the z-score\n",
    "    if verbose:\n",
    "        print('\\nCalculating z-scores: ' + seed_gene_file)\n",
    "    z_scores, final_heat, random_final_heats = calculate_heat_zscores(\n",
    "        individual_heats_matrix,\n",
    "        nodes,\n",
    "        dict(interactome.degree),\n",
    "        seed_genes,\n",
    "        num_reps=num_reps,\n",
    "        minimum_bin_size=minimum_bin_size)\n",
    "\n",
    "    # Save z-score results\n",
    "    z_scores.name = 'z-scores'\n",
    "    if save_z_scores:\n",
    "        z_scores.to_csv(out_z_file, sep='\\t')\n",
    "\n",
    "    # If save_final_heat is true, save out the final heat vector\n",
    "    if save_final_heat:\n",
    "        final_heat_df = pd.DataFrame(final_heat, columns=['z-scores'])\n",
    "        final_heat_df.to_csv(out_z_final_file, sep='\\t')\n",
    "\n",
    "    # If save_random_final_heats is true, save out the vector of randoms (this can be a large file)\n",
    "    if save_random_final_heats:\n",
    "        random_final_heats_df = pd.DataFrame(\n",
    "            random_final_heats.T,\n",
    "            index=nodes,\n",
    "            columns=range(1, random_final_heats.shape[0] + 1)\n",
    "        )\n",
    "        random_final_heats_df.to_csv(out_z_random_file, sep='\\t')\n",
    "\n",
    "    return z_scores, random_final_heats\n",
    "\n",
    "\n",
    "def calculate_heat_zscores(individual_heats_matrix, nodes, degrees, seed_genes, num_reps=1000,\n",
    "                           minimum_bin_size=10, random_seed=1):\n",
    "    \"\"\"\n",
    "    Helper function to perform network heat propagation using the given\n",
    "    individual heats matrix with the given seed genes and return the z-scores of\n",
    "    the final heat values of each node.\n",
    "\n",
    "    The z-scores are calculated based on a null model, which is built by running\n",
    "    the network propagation multiple times using randomly selected seed genes\n",
    "    with similar degree distributions to the original seed gene set.\n",
    "\n",
    "    The returned tuple contains the following:\n",
    "\n",
    "    * :py:class:`pandas.Series` containing z-scores for each gene. Gene names comprise the index column\n",
    "    * :py:class:`pandas.Series` containing the final heat scores for each gene. Gene names comprise the index column,\n",
    "    * :py:class:`numpy.ndarray` containing square matrix in which each row contains the final heat scores for each gene\n",
    "    from a network propagation from random seed genes)\n",
    "\n",
    "    :param individual_heats_matrix: output of the\n",
    "            netprop.get_individual_heats_matrix. A square matrix containing the\n",
    "            final heat contributions of each gene\n",
    "    :type individual_heats_matrix: :py:class:`numpy.ndarray`\n",
    "    :param nodes: nodes, in the order in which they were supplied to\n",
    "            the :py:func:`~netcoloc.netprop.get_normalized_adjacency_matrix` method\n",
    "            which returns the precursor to the individual_heats_matrix\n",
    "    :type nodes: list\n",
    "    :param degrees: Mapping of node names to node degrees\n",
    "    :type degrees: dict\n",
    "    :param seed_genes: list of genes to use for network propagation. The\n",
    "            results of this network propagation will be compared to a set of\n",
    "            random results in order to obtain z-scores\n",
    "    :type seed_genes: list\n",
    "    :param num_reps: Number of times the network propagation algorithm should\n",
    "            be run using random seed genes in order to build the null model\n",
    "    :type num_reps: int\n",
    "    :param minimum_bin_size: minimum number of genes that should be in\n",
    "            each degree matching bin\n",
    "    :type minimum_bin_size: int\n",
    "    :param random_seed:\n",
    "    :return: (:py:class:`pandas.Series`, :py:class:`pandas.Series`, :py:class:`numpy.ndarray`)\n",
    "    :rtype: tuple\n",
    "    \"\"\"\n",
    "    # set random seed for reproducibility\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "    # Calculate network propagation results given gene set\n",
    "    seed_genes = list(np.intersect1d(nodes, seed_genes))\n",
    "    final_heat = network_propagation(individual_heats_matrix, nodes, seed_genes)\n",
    "\n",
    "    # Initialize empty matrix for results of random network propagations\n",
    "    random_final_heats = np.zeros([num_reps, len(final_heat)])\n",
    "\n",
    "    # Create bins containing genes of similar degree\n",
    "    bins, actual_degree_to_bin_index = get_degree_binning(degrees, minimum_bin_size)\n",
    "\n",
    "    # Perform network propagation many times with random seed genes\n",
    "    for repetition in tqdm(range(num_reps)):\n",
    "        # Create list of random, degree-matched seed genes\n",
    "        random_seed_genes = []\n",
    "        for gene in seed_genes:\n",
    "            # Find genes with similar degrees to focal gene degree\n",
    "            degree = degrees[gene]\n",
    "            genes_of_similar_degree = bins[actual_degree_to_bin_index[degree]]\n",
    "            # Shuffle the genes in the bin\n",
    "            np.random.shuffle(genes_of_similar_degree)\n",
    "\n",
    "            # Add genes to list that haven't already been added\n",
    "            index = 0\n",
    "            while genes_of_similar_degree[index] in random_seed_genes:\n",
    "                index += 1\n",
    "            random_seed_genes.append(genes_of_similar_degree[index])\n",
    "\n",
    "        # Perform network propagation with random seed genes\n",
    "        random_final_heat = network_propagation(individual_heats_matrix, nodes, random_seed_genes)\n",
    "        # Set seeds to NaN so they don't bias results\n",
    "        random_final_heat.loc[random_seed_genes] = np.nan\n",
    "        # Add results to random_final_heats matrix\n",
    "        random_final_heats[repetition] = random_final_heat\n",
    "\n",
    "    # Calculate z-scores\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        z_scores = (np.log(final_heat) - np.nanmean(np.log(random_final_heats),\n",
    "                                                    axis=0)) / np.nanstd(np.log(random_final_heats), axis=0)\n",
    "\n",
    "    random_final_heats_df = pd.DataFrame(\n",
    "        random_final_heats.T,\n",
    "\tindex=nodes,\n",
    "\tcolumns=range(1, random_final_heats.shape[0] + 1))\n",
    "    random_final_heats_df.to_csv(out_z_random_file, sep='\\t')        \n",
    "    final_heat_df = pd.DataFrame(final_heat, columns=['z-scores'])\n",
    "    final_heat_df.to_csv(out_z_final_file, sep='\\t')\n",
    "    z_scores.to_csv(out_z_file, sep='\\t')    \n",
    "    return z_scores, final_heat, random_final_heats\n",
    "\n",
    "#change to 500, 100, 1000 before running job\n",
    "def calculate_heat_zscores_with_sampling(data, nodes, individual_heats, G_PC, trait=\"BMI\", max_genes=500,\n",
    "                                         num_samples=100,\n",
    "                                         nominal_sig=0.05, num_reps=1000, out_path=\"\", minimum_bin_size=10):\n",
    "    \"\"\"\n",
    "    Takes a set of summary statistics and a molecular interaction and performs sampling of the significant genes.\n",
    "    For each sample a random selection of seed genes is chosen, weighted by the p-value of each gene in the summary\n",
    "    statistics. Network propagation with zscore calculation is performed for each sample to generate a distribution\n",
    "    of z-scores for each gene in the seed_gene set.\n",
    "    :param data: Gene level summary statistics\n",
    "    :param nodes: list of nodes in the interaction network\n",
    "    :param individual_heats: Heat matrix calculated by `netprop_zscore.get_individual_heats_matrix())\n",
    "    :param G_PC: molecular interaction network\n",
    "    :param trait: name of trait being investigated\n",
    "    :param max_genes: Maximum number of seed genes to include in each sample (default=500, maximum=500)\n",
    "    :param num_samples: Number of times to perform sampling (default=100)\n",
    "    :param nominal_sig: Significance cutoff for keeping genes in data (Note: this value will be Bonferroni corrected)\n",
    "    :param num_reps: Number of repetitions of randomization for generating null distribution for z_scores\n",
    "    :param out_path: prefix for saving results of sampling\n",
    "    :param minimum_bin_size: minimum number of genes that should be in\n",
    "            each degree matching bin\n",
    "    :type minimum_bin_size: int\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert max_genes <= 500, \"NetColoc is only valid for sets of 500 or less genes so maximum number of genes for \" \\\n",
    "                             \"sampling must be <= 500\"\n",
    "    outfile = out_dir + '/'+ out_network + \"sampling_\" + str(max_genes) + \"_\" + str(num_samples) + \".tsv\"\n",
    "    \n",
    "    data = data.loc[data.gene_symbol.isin(nodes)]  # subset to genes in interaction network\n",
    "    all_seeds = data.loc[data.pvalue <= nominal_sig / len(data)]  # Bonferroni correction\n",
    "    all_seeds = all_seeds.assign(log10p=-1 * np.log10(all_seeds.pvalue))  # get -log10p for weighted sampling\n",
    "    sampling_results = []\n",
    "    for i in range(num_samples):\n",
    "        # perform propagation for sample\n",
    "        sample_seeds = random.choices(population=all_seeds.gene_symbol.values, weights=all_seeds.log10p.values, k=max_genes)\n",
    "        sample_results = calculate_heat_zscores(individual_heats, nodes=list(G_PC.nodes), degrees=dict(G_PC.degree),\n",
    "                                                seed_genes=sample_seeds, num_reps=num_reps,\n",
    "                                                minimum_bin_size=minimum_bin_size, random_seed=i)[0]\n",
    "        sample_z = pd.DataFrame(sample_results, columns=[\"z\" + str(i)])\n",
    "        # save running results of sampling\n",
    "        if i == 0:\n",
    "            sample_z.to_csv(outfile, sep=\"\\t\")\n",
    "        else:\n",
    "            existing = pd.read_csv(outfile, sep=\"\\t\", index_col=0)\n",
    "            existing = existing.join(sample_z)\n",
    "            existing.to_csv(outfile, sep=\"\\t\")\n",
    "        sampling_results.append(sample_z)\n",
    "\n",
    "    return pd.concat(sampling_results, axis=1)\n",
    "\n",
    "\n",
    "def get_consensus_z_scores(sampled_results, percentile=.75):\n",
    "    \"\"\"\n",
    "    returns the consensus z score for each gene across all samples\n",
    "    :param sampled_results: output of netprop_zscore.calculate_heat_zscores_with_sampling\n",
    "    :type sampled_results: str (file path) or pandas.DataFrame\n",
    "    :param percentile: Percentile cut off for determining consensus score (default=0.75)\n",
    "    :type percentile: float\n",
    "    :return: Consensus z-scores for all genes based on sampling\n",
    "    \"\"\"\n",
    "    if type(sampled_results) == str:\n",
    "        results = pd.read_csv(sampled_results, sep=\"\\t\", index_col=0)\n",
    "    else:\n",
    "        results = sampled_results\n",
    "    consensus_z = pd.DataFrame({'z': results.quantile(q=percentile, axis=1)})\n",
    "    return consensus_z\n",
    "\n",
    "\n",
    "#------------------ [10]\n",
    "if (len(hm_genes)>500):\n",
    "    sampled_data = calculate_heat_zscores_with_sampling(hm_df_subset, nodes, indiv_heats, G_PC, trait=\"BMI\")\n",
    "    z_hm = get_consensus_z_scores(sampled_data, percentile=0.75)\n",
    "else:\n",
    "    z_hm, Fnew_hm, Fnew_rand_hm = calculate_heat_zscores(w_double_prime, pc_nodes, dict(G_PC.degree), hm_genes)\n",
    "#100, 1000\n",
    "    z_hm = pd.DataFrame({'z':z_hm})\n",
    "#------------------ [11]\n",
    "print('\\nCalculating human gene z-scores: ')\n",
    "z_rn, Fnew_rn, Fnew_rand_rn = calculate_heat_zscores(w_double_prime, pc_nodes, dict(G_PC.degree), rn_genes, num_reps=10,minimum_bin_size=10)\n",
    "#100, 1000\n",
    "z_rn = pd.DataFrame({'z':z_rn})\n",
    "#------------------ [12]\n",
    "from scipy.stats import hypergeom\n",
    "from scipy.stats import norm\n",
    "\n",
    "# ------ customize this section based on your gene sets and how they should be labeled -------\n",
    "z_dict = {'hm_genes':z_hm,'rn_genes':z_rn}\n",
    "\n",
    "seed_dict = {'hm_genes':hm_genes,'rn_genes':rn_genes}\n",
    "# --------------------------------------------------------------------------------------------\n",
    "# save the num overlap and overlap p-val in dataframes\n",
    "focal_diseases = ['hm_genes','rn_genes']\n",
    "network_num_overlap = pd.DataFrame(np.zeros((len(focal_diseases),len(focal_diseases))),index=focal_diseases)\n",
    "network_num_overlap.columns = focal_diseases\n",
    "\n",
    "network_obs_exp = pd.DataFrame(np.zeros((len(focal_diseases),len(focal_diseases))),index=focal_diseases)\n",
    "network_obs_exp.columns = focal_diseases\n",
    "\n",
    "network_pval_overlap = pd.DataFrame(np.ones((len(focal_diseases),len(focal_diseases))),index=focal_diseases)\n",
    "network_pval_overlap.columns = focal_diseases\n",
    "\n",
    "network_exp_mean_overlap = pd.DataFrame(np.ones((len(focal_diseases),len(focal_diseases))),index=focal_diseases)\n",
    "network_exp_mean_overlap.columns = focal_diseases\n",
    "\n",
    "network_exp_std_overlap = pd.DataFrame(np.ones((len(focal_diseases),len(focal_diseases))),index=focal_diseases)\n",
    "network_exp_std_overlap.columns = focal_diseases\n",
    "\n",
    "zthresh=3\n",
    "for i in np.arange(len(focal_diseases)-1):\n",
    "    for j in np.arange(1+i,len(focal_diseases)):\n",
    "        d1=focal_diseases[i]\n",
    "        d2=focal_diseases[j]\n",
    "        \n",
    "        seed1 = seed_dict[d1]\n",
    "        seed2 = seed_dict[d2]\n",
    "        \n",
    "        z1=z_dict[d1]\n",
    "        z1_noseeds = z1.drop(list(np.intersect1d(seed1+seed2,z1.index.tolist())))\n",
    "        z2=z_dict[d2]\n",
    "        z2_noseeds = z2.drop(list(np.intersect1d(seed1+seed2,z2.index.tolist())))\n",
    "        # replace hypergeometric with permutation empirical p\n",
    "#         z_d1d2_size,high_z_rand=network_colocalization.calculate_expected_overlap(d1,d2,z1_noseeds,z2_noseeds,\n",
    "#                                                            plot=False,numreps=1000,zthresh=zthresh)\n",
    "\n",
    "        z_d1d2_size,high_z_rand=network_colocalization.calculate_expected_overlap(z_scores_1=z1['z'],z_scores_2=z2['z'],z1_threshold= 1.5,z2_threshold= 1.5,\n",
    "                                                           z_score_threshold=zthresh,num_reps=1000, plot=False)        \n",
    "        ztemp = (z_d1d2_size-np.mean(high_z_rand))/np.std(high_z_rand)\n",
    "        ptemp = norm.sf(ztemp)\n",
    "        print(d1+' + '+d2)\n",
    "        print('size of network intersection = '+str(z_d1d2_size))\n",
    "        print(z_d1d2_size)\n",
    "        print(np.mean(high_z_rand))\n",
    "        obs_exp_temp = float(z_d1d2_size)/np.mean(high_z_rand)\n",
    "        print('observed size/ expected size = ' + str(obs_exp_temp))\n",
    "        print('p = '+ str(ptemp))\n",
    "        \n",
    "        \n",
    "        network_num_overlap.loc[d1][d2]=z_d1d2_size\n",
    "        network_num_overlap.loc[d2][d1]=z_d1d2_size\n",
    "\n",
    "        network_pval_overlap.loc[d1][d2]=ptemp\n",
    "        network_pval_overlap.loc[d2][d1]=ptemp\n",
    "        \n",
    "        network_obs_exp.loc[d1][d2]=obs_exp_temp\n",
    "        network_obs_exp.loc[d2][d1]=obs_exp_temp\n",
    "        \n",
    "        network_exp_mean_overlap.loc[d1][d2]=np.mean(high_z_rand)\n",
    "        network_exp_mean_overlap.loc[d2][d1]=np.mean(high_z_rand)\n",
    "        \n",
    "        network_exp_std_overlap.loc[d1][d2]=np.std(high_z_rand)\n",
    "        network_exp_std_overlap.loc[d2][d1]=np.std(high_z_rand)\n",
    "        overlap_values = [z_d1d2_size, high_z_rand, obs_exp_temp, ptemp]\n",
    "#------------------ [13]\n",
    "# select genes in network intersection, make a subgraph\n",
    "d1='hm_genes'\n",
    "d2='rn_genes'\n",
    "z1=z_dict[d1]\n",
    "z2=z_dict[d2]\n",
    "\n",
    "G_overlap = network_colocalization.calculate_network_overlap_subgraph(G_PC,z1['z'],z2['z'],z_score_threshold=3)\n",
    "#print(len(G_overlap.nodes()))\n",
    "#print(len(G_overlap.edges()))\n",
    "#------------------ [14]\n",
    "# compile dataframe of metadata for overlapping nodes\n",
    "node_df = pd.DataFrame(index=list(G_overlap.nodes))\n",
    "node_df[d1+'_seeds']= 0\n",
    "node_df[d2+'_seeds']= 0\n",
    "node_df[d1+'_seeds'].loc[list(np.intersect1d(seed_dict[d1],node_df.index.tolist()))]=1\n",
    "node_df[d2+'_seeds'].loc[list(np.intersect1d(seed_dict[d2],node_df.index.tolist()))]=1\n",
    "node_df['z_'+d1]=z1.loc[list(G_overlap.nodes)]['z']\n",
    "node_df['z_'+d2]=z2.loc[list(G_overlap.nodes)]['z']\n",
    "node_df['z_both']=node_df['z_'+d1]*node_df['z_'+d2]\n",
    "\n",
    "node_df = node_df.sort_values('z_both',ascending=False)\n",
    "#------------------ [15]\n",
    "mean_highz= np.mean(high_z_rand)\n",
    "stdev_highz=np.std(high_z_rand)\n",
    "nhgenes=len(hm_df)\n",
    "nrgenes=len(rn_df)\n",
    "overlap_values = [overlap_label ,str(z_d1d2_size), str(mean_highz), str(stdev_highz), str(obs_exp_temp), str(ptemp), str(nhgenes), str(nrgenes)]\n",
    "#------------------ [16]\n",
    "#write output files\n",
    "#out_overlap_file\n",
    "#out_network_file\n",
    "#with open(out_overlap_file, 'a+')  # open file in append mode\n",
    "#f.write('\\n' overlap_values)\n",
    "sourceFile = open(out_overlap_file, 'a+')\n",
    "joined_list = '\\t'.join(overlap_values)\n",
    "print(joined_list , file = sourceFile)\n",
    "sourceFile.close()\n",
    "with open(out_network_file, 'w') as f:\n",
    "    f.write(tabulate(node_df))\n",
    "#------------------ [17]\n",
    "# ----- a number of properties should be customized here ------\n",
    "#Annotate network\n",
    "G_overlap_cx = ndex2.create_nice_cx_from_networkx(G_overlap)\n",
    "G_overlap_cx.set_name(out_network) \n",
    "for node_id, node in G_overlap_cx.get_nodes():\n",
    "    data = node_df.loc[node['n']]\n",
    "    for row, value in data.items():\n",
    "        if row == 'hm_seeds' or row == 'rn_seeds':\n",
    "            data_type = 'boolean'\n",
    "            if value == 0:\n",
    "                value = False\n",
    "            else:\n",
    "                value = True\n",
    "        else:\n",
    "            data_type = 'double'\n",
    "        G_overlap_cx.set_node_attribute(node_id, row, value, type=data_type)\n",
    "#Upload to NDEx\n",
    "SERVER ='ndexbio.org'\n",
    "USERNAME = ndex_user\n",
    "PASSWORD = ndex_password\n",
    "network_uuid = G_overlap_cx.upload_to(SERVER, USERNAME, PASSWORD)\n",
    "#------------------ [18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Combine the network overlap files for all different genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat ~/*/network_overlap.txt > ~/network_overlap.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_overlap_BMI=pd.read_csv('control trait network overlap/network_overlap.tsv',header=None, sep=\"\\t\")\n",
    "#overlap_values = [overlap_label ,str(z_d1d2_size), str(mean_highz), str(stdev_highz), str(obs_exp_temp), str(ptemp), str(nhgenes), str(nrgenes)]\n",
    "\n",
    "net_overlap_BMI.columns = ['neale_trait' ,'rat_trait', 'z_size_d1d2','mean_high_z_rand', 'stdev_highz', 'obs_exp_temp', 'ptemp', 'nhgenes', 'nrgenes']\n",
    "net_overlap_BMI.neale_trait = net_overlap_BMI.neale_trait.apply(lambda x: x.replace(\"*.gwas.imp\", \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Calculate values for plotting functions in net_overlap_BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "net_overlap_BMI.yerr_lower = net_overlap_BMI.obs_exp_temp - (net_overlap_BMI.z_size_d1d2 / (net_overlap_BMI.mean_high_z_rand + (1.96 * net_overlap_BMI.stdev_highz)))\n",
    "net_overlap_BMI.yerr_upper = net_overlap_BMI.z_size_d1d2 / (net_overlap_BMI.mean_high_z_rand - (1.96 * net_overlap_BMI.stdev_highz)) - net_overlap_BMI.obs_exp_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "add in meta data (manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_subset = manifest.loc[manifest.Sex=='both_sexes']\n",
    "\n",
    "net_overlap_BMI= net_overlap_BMI.merge(man_subset.iloc[:, 1:2], left_on='neale_trait', right_on='Phenotype Code', how=\"left\")\n",
    "net_combined_BMI= net_overlap_BMI.merge(corr_raw_bmi.loc[:, (\"Description\", \"rg\", \"rg.SE\")], \n",
    "                                        left_on=\"Phenotype Description\", right_on=\"Description\", how=\"left\")\n",
    "\n",
    "hr_tbl_distinct = hr_tbl.drop_duplicates(subset=[\"description\"])\n",
    "\n",
    "net_combined_BMI = net_combined_BMI.merge(hr_tbl.loc[:, ('phenotype', 'h2_observed', 'h2_observed_se', 'h2_liability',\n",
    "                                                         'h2_liability_se', 'n','variable_type')], left_on=\"neale_trait\", right_on=\"phenotype\",\n",
    "                                         how=\"left\")\n",
    "net_combined_BMI = net_combined_BMI.loc[net_combined_BMI.z_size_d1d2 != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Calculate number of significant human genes per file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "bash tabulate_siggenes_totable.py \"$file\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "tabulate_siggenes_totable.py\n",
    "\n",
    "```\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import numpy as np\n",
    "\n",
    "human_raw_file = sys.argv[1]\n",
    "\n",
    "out_file = 'human_sig_genes.txt'\n",
    "\n",
    "pc_nodes=(pd.read_csv('/home/bsleger/bsl/bmi_net/neale_runscripts/pcnet_node_list.tsv',header=None, sep=\"\\t\"))\n",
    "pc_nodes=(pc_nodes.iloc[:, 0]).tolist()\n",
    "\n",
    "#read in data files (netcoloc)\n",
    "hm_df = pd.read_csv(human_raw_file, sep=\"\\t\")\n",
    "\n",
    "#format human data file - subset to significant gene associations (0.05 corrected by bonferroni)\n",
    "#df[df.Length > 7] df.column.isin(values)\n",
    "alpha= 0.05\n",
    "m=22136\n",
    "N=500\n",
    "alpha_corrected = alpha/m\n",
    "\n",
    "print(len(hm_df))\n",
    "hm_df_subset=hm_df[hm_df.gene_symbol.isin(pc_nodes)]\n",
    "hm_df_subset=hm_df[hm_df.pvalue<=(alpha_corrected)]\n",
    "print(len(hm_df_subset))\n",
    "hm_genes=hm_df_subset.index.tolist()\n",
    "#hm_df_subset = hm_df_subset.sort_values('pvalue',ascending = True).head(500)\n",
    "\n",
    "\n",
    "with open(out_file, 'a') as f:\n",
    "        f.write(human_raw_file+ '\\t'+ str(len(hm_genes))+ '\\n')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Read in a table of the number of significant human genes per file first considered as potential seeds, merge with net_combined_BMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NHumanGenes=pd.read_csv(\"human_sig_genes.txt\", sep=\"\\t\", header=None)\n",
    "NHumanGenes.columns = [\"file\",\"NHumanGenes\"]\n",
    "\n",
    "def getNealeTrait(fstr):\n",
    "    tstr = fstr[40:(len(fstr) - 51)]\n",
    "    if \"GIANT\" in fstr:\n",
    "        tstr = fstr[40:(len(fstr) - 26)]\n",
    "    if \"gwas\" in fstr:\n",
    "        tstr = tstr[0:(len(tstr) - 9)]\n",
    "    return tstr\n",
    "        \n",
    "NHumanGenes.neale_trait = NHumanGenes.file.apply(getNealeTrait)\n",
    "net_combined_BMI = net_combined_BMI.merge(NHumanGenes.loc[:, ('neale_trait', 'NHumanGenes')], on=\"neale_trait\", how=\"left\")\n",
    "\n",
    "#get distinct network overlap\n",
    "net_combined_BMI = net_combined_BMI.drop_duplicates(subset=[\"neale_trait\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "subset net_combined_BMI of heritability of +/- .1 of BMI (.25), N Human Genes implicated from PASCAL>=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_bin=net_combined_BMI.loc[net_combined_BMI.variable_type=='binary']\n",
    "net_bin=net_bin.loc[net_bin.h2_liability<0.35]\n",
    "net_bin=net_bin.loc[net_bin.h2_liability>0.15]\n",
    "\n",
    "net_lin=net_combined_BMI.loc[net_combined_BMI.variable_type!='binary']\n",
    "net_lin=net_lin.loc[net_lin.h2_liability<0.35]\n",
    "net_lin=net_lin.loc[net_lin.h2_liability>0.15]\n",
    "net_combined_BMI = pd.concat([net_bin, net_lin, net_combined_BMI.loc[net_combined_BMI.neale_trait==\"GIANT_BMI\"]], axis=1)\n",
    "net_combined_BMI = net_combined_BMI.loc[~net_combined_BMI.neale_trait.isna()]\n",
    "net_combined_BMI = net_combined.drop_duplicates(subset=[\"neale_trait\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## make final table for labeling genetic correlation values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "net_combined_BMI_corr=net_combined_BMI.loc[~net_combined_BMI.rg.isna()]\n",
    "stdev_rg = np.nanstd(net_combined_BMI_corr.rg)\n",
    "mean_rg = np.nanmean(net_combined_BMI_corr.rg)\n",
    "net_combined_BMI_corr[\"rg_zscore\"] = (net_combined_BMI_corr.rg - mean_rg / stdev_rg)\n",
    "net_combined_BMI_corr[\"rg_abs\"] = np.abs(net_combined_BMI_corr.rg)\n",
    "net_combined_BMI_corr=net_combined_BMI_corr.drop_duplicates(subset=[\"neale_trait\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#write table for network overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_combined_BMI.to_csv(DATADIR + \"outputs/controls/network_combined_BMI.txt\", sep=\"\\t\", index=False)\n",
    "net_combined_BMI_corr.to_csv(DATADIR + \"outputs/controls/network_combined_BMI_corr.txt\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python [conda env:rat_pub]",
   "language": "python",
   "name": "conda-env-rat_pub-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
