import pandas as pd
import numpy as np
import networkx as nx
import ndex2
from getpass import getpass
from updated_netcoloc_functions import get_p_from_permutation_results

from statsmodels.stats.multitest import fdrcorrection
from scipy.stats import hypergeom
from statsmodels.stats import contingency_tables

def load_human_seed_genes(filepath, interactome_nodes, trait=''):
    """
    Takes a gene level p-value file (e.g. generated by PASCAL) and extracts Bonferroni significant genes that exist
    within the chosen biological network
    :param filepath: seed gene file to be imported. This file must have 'gene_symbol' and 'pvalue' columns.
    :type filepath: str
    :param interactome_nodes: A list of nodes (gene symbols) in the interactome being used
    :type interactome_nodes: list
    :param trait: The trait represented by the seed genes
    :type trait: str
    :return: A list of seed genes meeting a bonferroni corrected pvalue < 0.05
    :rtype: list
    """
    all_scores = pd.read_csv(filepath, sep="\t", index_col='gene_symbol')
    # subset to genes in the interactome
    all_scores = all_scores.loc[list(np.intersect1d(all_scores.index.tolist(), interactome_nodes))]
    # Calculate bonferroni corrected pvalue (alpha=0.05)
    bonf_p = .05/len(all_scores)
    # Get significant genes
    seeds = all_scores[all_scores['pvalue'] < bonf_p].index.tolist()
    print("Number of",trait,"seeds:", len(seeds))
    return seeds


def load_pcnet():
    """
    Loads the PCNet network from NDEx and returns a list of nodes in the network and a networkx graph object of the network
    :return nodes: list of nodes in the PCNet Network
    :rtype nodes: list
    :return G_int: The PCNet network
    :rtype G_int: :py:class:`networkx.Graph`
    """
    interactome_uuid='4de852d9-9908-11e9-bcaf-0ac135e8bacf' # for PCNet
    # interactome_uuid='275bd84e-3d18-11e8-a935-0ac135e8bacf' # for STRING high confidence
    ndex_server='public.ndexbio.org'
    ndex_user=None
    ndex_password=None
    G_int = ndex2.create_nice_cx_from_server(
            ndex_server, 
            username=ndex_user, 
            password=ndex_password, 
            uuid=interactome_uuid
        ).to_networkx()
    nodes = list(G_int.nodes)

    # pcnet appears to have some self edges... should remove them. 
    G_int.remove_edges_from(nx.selfloop_edges(G_int))

    # print out interactome num nodes and edges for diagnostic purposes
    print('number of nodes:')
    print(len(G_int.nodes))
    print('\nnumber of edges:')
    print(len(G_int.edges))
    return nodes, G_int


def load_network(uuid='e8cc9239-d91a-11eb-b666-0ac135e8bacf', use_password=False):
    """
    Wrapper function for loading a network from NDEx
    :param uuid: NDEx identifier
    :type uuid: str
    :param use_password: default = False, set True if the network is not public
    :type use_password: bool
    :return: A networkx object of the desired network
    :rtype: :py:class:`networkx.Graph`
    """
    ndex_server='public.ndexbio.org'
    if use_password:
        ndex_user=getpass.getpass("NDEX Username:")
        ndex_password=getpass.getpass("NDEX Password:")
    else:
        ndex_user=None
        ndex_password=None
    G_overlap_cx = ndex2.create_nice_cx_from_server(
            ndex_server, 
            username=ndex_user, 
            password=ndex_password, 
            uuid=uuid)
    G_overlap = G_overlap_cx.to_networkx()
    print('number of nodes:')
    print(len(G_overlap.nodes))
    print('\nnumber of edges:')
    print(len(G_overlap.edges))
    return G_overlap


def get_permutation_stats(obs, perm, trait, ci=0.95):
    """
    Calculates the mean observed/expected value as well as upper and lower bounds on the O/E value based on a confidence interval.
    Evaluates the significance of the mean using a Z test.
    :param obs: The observed value
    :type obs: float
    :param perm: colleciton of permuted values
    :type perm: list, :py:class:`numpy.ndarray`
    :param trait: the trait represented by `obs` and `perm` to be used to name the results
    :type trait: str
    :param ci: Confidence interval to be reported (default = 0.95)
    :type ci: float
    :return: The mean o/e, upper bound, lower bound and Z-score pvalue for the trait
    :rtype: :py:class:`pandas.DataFrame`
    """
    transform = obs / perm
    avg = np.mean(transform)
    upper = np.quantile(transform, ci)
    lower = np.quantile(transform, 1-ci)
    p_value = get_p_from_permutation_results(obs, perm)
    return pd.DataFrame({"Mean":avg, "Upper":upper, "Lower":lower, "p":p_value}, index=[trait])


def get_consensus_z_scores(sampled_results, percentile=.75):
    """
    returns the consensus z score for each gene across all samples
    :param sampled_results: output of netprop_zscore.calculate_heat_zscores_with_sampling
    :type sampled_results: str (file path) or :py:class:`pandas.DataFrame`
    :param percentile: Percentile cut off for determining consensus score (default=0.75)
    :type percentile: float
    :return: Consensus z-scores for all genes based on sampling
    :rtype: :py:class:`pandas.DataFrame`
    """
    if type(sampled_results) == str:
        results = pd.read_csv(sampled_results, sep="\t", index_col=0)
    else:
        results = sampled_results
    consensus_z = pd.DataFrame({'z': results.quantile(q=percentile, axis=1)})
    return consensus_z

## Utilities for MGD Analysis ------------------------------------------------------------

def num_to_mp(number):
    """
    Converts a number into a mammalian phenotype code. For example 5678 becomes 'MP:0005678'
    :param number: numeric suffix of a mammalian phenotype code
    :type number: int
    :return: The corresponding mammalian phenotype code
    :rtype: str
    """
    mp = "MP:"
    num = str(number)
    zeros_to_add = 7-len(num)
    mp = [mp] + ["0"] * zeros_to_add + [num]
    return "".join(mp)


def get_MP_description(term, MPO):
    """
    Extract the description of a mammalian phenotype code from the ontology
    :param term: term of interest
    :type term: str
    :param MPO: The mammalian phenotype ontology
    :type MPO: :py:class:`ddot.Ontology` 
    :return: plain english description of phenotype
    :rtype: str
    """
    return MPO.node_attr.loc[term].description


def get_mp_graph(datafile="parsed_mp.txt"):
    """
    Converts the mammalian phenotype onotology into a networkx graph
    :param datafile: File path to the parsed mammalian phenotype data
    :type datafile: str
    :return: A directed graph representing the mammalian phenotype ontology
    :rtype: :py:class:`networkx.DiGraph`
    """
    mp_data = pd.read_csv(datafile, sep="\t", header=None)
    mp_data.head()
    mp_graph = nx.from_pandas_edgelist(mp_data, 0,1, create_using=nx.DiGraph)
    return mp_graph


def get_top_level_terms(mp_graph, root="MP:0000001" ,exclude=["MP:0003012", "MP:0002873"]):
    """
    Retrieve all direct descendents of a mammalian phenotype term
    :param mp_graph: The graph representing the mammalian phenotype terms
    :type mp_graph: :py:class:`networkx.DiGraph`
    :param root: The parent term. Default = 'MP:0000001' - mammalian phenotype
    :type root: str
    :param exclude: Any terms to exlcude. Default = ["MP:0003012", "MP:0002873"] - 'no phenotypic analysis' and 'normal phenotype'
    :type exclude: list
    :return: All child terms of `root` except those in `exclude`
    :rtype: list of str
    """
    return [node for node in nx.dfs_preorder_nodes(mp_graph, root, 1) if node not in exclude][1:]


def change_symbols(mgi_data, pc_node_map):
    """
    Update the gene symbols in the mgi data to match updated gene symbols in the interaction network
    :param mgi_data: dataframe of mgi data
    :type mgi_data: :py:class:`pandas.DataFrame`
    :param pc_node_map: DataFrame mapping nodes in interaction network to updated symbols
    :type pc_node_map: :py:class:`pandas.DataFrame`
    :return: `mgi_data` with 'human_ortholog' column updated
    :rtype: :py:class:`pandas.DataFrame`
    """
    symbol_map = pd.Series(pc_node_map.index.values, index=pc_node_map["symbol"]).to_dict()
    mgi_data["human_ortholog"] = mgi_data["human_ortholog"].map(symbol_map)
    return mgi_data


def get_gene_hits_no_annotation(genes, term, MPO, term_mapping):
    """
    Retrieve the subset of genes that are mapped to a given term (or any of it's children in the mammalian phenotype ontology by MGI
    :param genes: Set of genes to test for membership
    :type genes: list
    :param term: A mammalian phenotype identifier e.g. MP:0005378
    :type term: str
    :param MPO: Mammalian phenotype ontology with gene mappings from MGI
    :type MPO: :py:class:`ddot.Ontology`
    :param term_mapping: Dictionary of all MPO terms and their associated genes.
    :type term_mapping: dict
    :return: Subset of 'genes' that are mapped to 'term' in the MGI
    :rtype: set
    """
    term_genes = [MPO.genes[idx] for idx in term_mapping[term]]
    overlap = set(genes).intersection(set(term_genes))
    return overlap


## Enrichment Analysis ---------------------------------------------------

def genes_per_node(MPO):
    """
    Summarizes the gene-term mappings contained in the ontology
    :param MPO: Mammalian phenotype ontology with gene mappings from MGI
    :type MPO: :py:class:`ddot.Ontology`
    :return counts: The number of unique genes associated with a term or any of its children 
    :rtype counts: dict
    :return genes: All unique terms to which a gene is mapped
    :rtype genes: dict
    :return results: All unique genes associated with a term or any of its children
    :rtype results: dict
    """
    node_order = MPO.topological_sorting(top_down=False)
    nodes = [i for i in node_order]
    results = {i: set(MPO.term_2_gene[i]) for i in node_order}
    genes = {i: set(MPO.gene_2_term[i]) for i in MPO.genes}
    # go through all terms and assign child results to the parent
    while len(nodes) > 0:
        current = nodes.pop()
        children = MPO.parent_2_child[current]
        if len(children) > 0:
            for child in children:
                if child != current:
                    results[current] = results[current].union(results[child])
        for gene in results[current]:
            if gene not in genes.keys():
                genes[gene] = set([current])
            else:
                genes[gene] = genes[gene].union(set([current]))
        else:
            pass
    counts = {k: len(results[k]) for k in results.keys()}
    return counts, genes, results


def community_term_enrichment(community_name, hier_df, MPO, mgi_df, term_counts, gene_to_terms, G_int, keep_genes=None, exclude_genes=None):
    """
    Takes a community and tests the genes in this community for enrichment of genes associated with phenotypes in MGI
    :param community_name: Index of the community to test
    :type community_name: str
    :param hier_df: Dataframe containing the genes in each community as produced by HiDeF
    :type hier_df: :py:class:`pandas.DataFrame`
    :param MPO: Mammalian phenotype ontology with gene mappings from MGI
    :type MPO: :py:class:`ddot.Ontology`
    :param mgi_df: Gene phenotype mapping
    :type mgi_df: :py:class:`pandas.DataFrame`
    :param term_counts: Number of genes associated with each term, produced by :py:func:`genes_per_node`
    :type term_counts: dict
    :param gene_to_terms: Number of terms associated with each gene, produced by :py:func:`genes_per_node`
    :type gene_to_terms: dict
    :param keep_genes: List of genes to maintain in the analysis - ONLY these genes will be kept
    :type keep_genes: list
    :param exclude_genes: List of genes to exclude from the analysis
    :type exclude_genes: list
    :return: The enrichment statistics for `community` for all terms in MPO
    :rtype: :py:class:`pandas.DataFrame`
    """
    # get the genes in the community
    genes = hier_df.loc[community_name, "CD_MemberList"]
    if type(genes) is str:  # split into a list of genes
        genes_all = genes.split(" ")
        N_hier = len(genes_all)
    else:
        genes_all = genes
        N_hier = len(genes_all)
    # only keep genes in the MGI ontology    
    genes = [ g for g in genes_all if g in MPO.genes ]  
    
    # subset genes based on input
    if keep_genes is not None:
        genes = [g for g in genes if g in keep_genes]
        N_hier = len([g for g in genes_all if g in keep_genes])
    if exclude_genes is not None:
        genes = [g for g in genes if g not in exclude_genes]
        N_hier = len([g for g in genes_all if g not in exclude_genes])
    
    # exit if there are no genes remaining
    if len(genes) == 0:
        print("0/"+str(len(genes_all)), "in MPO.genes/seeds")
        return pd.DataFrame()
    
    # Get the terms associated with these genes
    terms = []
    for gene in genes:
        terms += list(gene_to_terms[MPO.genes.index(gene)])

    # Join term totals and observed
    to_test = pd.DataFrame(pd.Series(terms, name="observed").value_counts()).join(pd.Series(term_counts, name="total"))
    M_pool_size = len(G_int.nodes())
    
    # Get odss ratio, p value of odds ratio, and 95% confidence interval
    OR_test = to_test.apply(lambda x: get_contingency_stats(x.observed, x.total, N_hier, M_pool_size), axis=1)
    try: 
        OR_test = pd.concat(list(OR_test), ignore_index=True)
    except TypeError:
        print(OR_test)
        print(N_hier, terms)
    OR_test.index = to_test.index
    to_test = pd.concat([to_test, OR_test], axis=1)
    
    to_test = to_test.assign(hyper_p=lambda z: hypergeom.sf(k=z.observed, M=M_pool_size, n=z.total, N=N_hier))
    desc = MPO.node_attr.loc[to_test.index]
    to_test = to_test.assign(sig_5e6=to_test["hyper_p"] < 5e-6)
    to_test = to_test.join(desc, how="left")
    to_test = to_test.assign(size=N_hier)
    return to_test


def get_contingency_stats(observed, term_size, community_size, network_size):
    """
    Calculates enrichment statistics for the number of genes associated with a term using a chi-squared test.
    :param observed: The number of community genes associated with a term
    :type observed: int
    :param term_size: The total number of genes associated with a term
    :type term_size: int
    :param community_size: The total number of genes in a community
    :type community_size: int
    :param network_size: The gobal network size
    :type network_size: int
    :return: The odds ratio, p value and confidence interval for observed enrichment
    :rtype: :py:class:`pandas.DataFrame`
    """
    q00 = observed
    q01 = term_size - observed
    q10 = community_size - observed
    q11 = network_size - q00 - q01 - q10
    results_table = [[q00, q01], [q10, q11]]
    #print(results_table)
    CT = contingency_tables.Table2x2(results_table)
    OR_p_temp = CT.oddsratio_pvalue()
    OR_CI_temp = CT.oddsratio_confint()
    OR = CT.oddsratio
    #print(CT.chi2_contribs)
    #return CT
    return pd.DataFrame({"OR":OR, "OR_p": OR_p_temp, "OR_CI_lower":OR_CI_temp[0], "OR_CI_upper":OR_CI_temp[1]}, index=[0])

## Results ------------------------------------------------------------------------------

def get_hits(network_results, data, p=0.01, OR=2, obs_min=3, total=10000, level= 3):
    """
    :param network_results: #TODO
    :type network_results: :py:class:`pandas.DataFrame`
    :param data: #TODO
    :type data: :py:class:`pandas.DataFrame`
    :param p: p-value threshold (default=0.01)
    :type p: float
    :param OR: odds ratio thereshold (default=2)
    :type OR: float
    :param obs_min: minimum number of observed genes (default=3)
    :type obs_min: int
    :param total: maximum number of genes per term (default=10000)
    :type total: int
    :param level: Minimum depth in the MPO ontology
    :type level: int 
    :return: The terms that meet the minimum criteria to be hits and their associated statistics
    :rtype: :py:class:`pandas.DataFrame`
    """
    mp_graph = get_mp_graph()
    # get the depths of all terms
    node_levels = nx.shortest_path_length(mp_graph, "MP:0000001")
    term_totals = data.loc[:, ("total", "description")]
    network_results = network_results.join(term_totals, how="left").drop_duplicates(subset=["OR", "total"])
    network_results = network_results.assign(depth=[node_levels[node] for node in network_results.index])
    try: # filter down to only the hits meeting criteria
        hits = network_results.loc[network_results.obs >= obs_min].loc[network_results.OR >= OR]
        hits = hits.loc[network_results.q >= -1 * np.log10(p)]
        hits = hits.loc[network_results.total <= total]
        hits = hits.loc[network_results.depth >= level]
        # if there are parents in the hits then keep the parents and not the children
        subG = G.subgraph(hits.index)       
        keep_nodes = [node for node in subG.nodes if subG.in_degree[node]==0]
        #keep_nodes = [node for node in subG.nodes if (subG.in_degree[node] == 0 and subG.out_degree[node] == 0) or 
        #             (subG.in_degree[node] == 0 and subG.out_degree[node] > 1) or 
        #              (subG.out_degree[node] == 0 and subG.out_degree[subG.predecessors(node)[0]] == 1)]
        hits = hits.loc[keep_nodes]
        return hits
    except:
        print("no hits passing filters")